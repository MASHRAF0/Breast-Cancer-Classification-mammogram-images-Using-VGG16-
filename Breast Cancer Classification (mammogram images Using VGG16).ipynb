{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17ab5b5f",
   "metadata": {},
   "source": [
    "### Introduction :\n",
    "\n",
    "We'll work with the VGG16 architecture, using weights that have been trained in ImageNet. We'll walk through three different ways to use its architecture and fine-tune it to be used for classification of dense vs. fatty breast tissue on mammogram images (Betweem Dense, and fatty ).\n",
    "\n",
    "The three scenarios for you to try are the following:\n",
    "\n",
    "* Freeze all layers except for the final convolutional layer of VGG16.\n",
    "* Freeze all layers except the final convolutional layer of VGG16, and add several dense (fully connected) layers.\n",
    "* Freeze all layers except the final convolutional layer of VGG16, and add several dense (fully connected) layers with dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b1276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob as gb\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5a268d",
   "metadata": {},
   "source": [
    "## Data Preprocessing for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460499a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "valid_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51d869e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mdb293.pgm.png</td>\n",
       "      <td>fatty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mdb297.pgm.png</td>\n",
       "      <td>fatty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mdb299.pgm.png</td>\n",
       "      <td>fatty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mdb315.pgm.png</td>\n",
       "      <td>dense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mdb317.pgm.png</td>\n",
       "      <td>dense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_path  class\n",
       "0  mdb293.pgm.png  fatty\n",
       "1  mdb297.pgm.png  fatty\n",
       "2  mdb299.pgm.png  fatty\n",
       "3  mdb315.pgm.png  dense\n",
       "4  mdb317.pgm.png  dense"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e954dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the image size from the input layer data of VGG16 Architecture.\n",
    "IMG_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e150f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_idg = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = False,\n",
    "    height_shift_range = 0.1,\n",
    "    width_shift_range = 0.1,\n",
    "    shear_range = 0.1,\n",
    "    rotation_range = 20,\n",
    "    zoom_range = 0.1\n",
    ")\n",
    "\n",
    "train_gen = train_idg.flow_from_dataframe(\n",
    "    dataframe = train_df,\n",
    "    x_col = 'img_path',\n",
    "    y_col = 'class',\n",
    "    class_mode = 'binary',\n",
    "    batch_size = 3,\n",
    "    target_size = IMG_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11ded4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_idg = ImageDataGenerator(\n",
    "    rescale = 1./255.0\n",
    ")\n",
    "\n",
    "val_gen = val_idg.flow_from_dataframe(\n",
    "    dataframe = valid_df,\n",
    "    x_col = 'img_path',\n",
    "    y_col = 'class',\n",
    "    class_mode = 'binary',\n",
    "    batch_size = 3,\n",
    "    target_size = IMG_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b84b92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull a single large batch of random validation data for testing after each epoch\n",
    "testx, testy = val_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07521ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfac30a",
   "metadata": {},
   "source": [
    "## Model building & Fine Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650dd4f1",
   "metadata": {},
   "source": [
    "#### 1.Freeze all layers except for the final convolutional layer of VGG16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbf968d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d8d8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer layer is the last layer before the flatten layer\n",
    "transfer_layer = model.get_layer('block5_pool')\n",
    "vgg_model = Model(inputs=model.input,\n",
    "                   outputs=transfer_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78c559bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg_model.layers[0:17]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "866dfa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "block1_conv1 False\n",
      "block1_conv2 False\n",
      "block1_pool False\n",
      "block2_conv1 False\n",
      "block2_conv2 False\n",
      "block2_pool False\n",
      "block3_conv1 False\n",
      "block3_conv2 False\n",
      "block3_conv3 False\n",
      "block3_pool False\n",
      "block4_conv1 False\n",
      "block4_conv2 False\n",
      "block4_conv3 False\n",
      "block4_pool False\n",
      "block5_conv1 False\n",
      "block5_conv2 False\n",
      "block5_conv3 True\n",
      "block5_pool True\n"
     ]
    }
   ],
   "source": [
    "for layer in vgg_model.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "310bf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "# The pre-trained architecture\n",
    "new_model.add(vgg_model)\n",
    "# Flatten the output of the VGG16 model because it is from a convolutional layer.\n",
    "new_model.add(Flatten())\n",
    "#The output layer\n",
    "new_model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39f3793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    optimizer= Adam(learning_rate= 0.0001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91cd2bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 3s 403ms/step - loss: 0.8378 - binary_accuracy: 0.5000 - val_loss: 0.6203 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 3s 371ms/step - loss: 0.5819 - binary_accuracy: 0.8000 - val_loss: 0.7146 - val_binary_accuracy: 0.6667\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 3s 398ms/step - loss: 0.5081 - binary_accuracy: 0.7000 - val_loss: 0.6094 - val_binary_accuracy: 0.6667\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 4s 659ms/step - loss: 0.4329 - binary_accuracy: 0.7500 - val_loss: 0.4655 - val_binary_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 4s 609ms/step - loss: 0.4494 - binary_accuracy: 0.8000 - val_loss: 0.5020 - val_binary_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 4s 607ms/step - loss: 0.3013 - binary_accuracy: 0.9000 - val_loss: 0.5104 - val_binary_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 4s 553ms/step - loss: 0.2757 - binary_accuracy: 0.9000 - val_loss: 0.6187 - val_binary_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 4s 557ms/step - loss: 0.2107 - binary_accuracy: 0.9500 - val_loss: 0.5673 - val_binary_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 4s 555ms/step - loss: 0.1244 - binary_accuracy: 1.0000 - val_loss: 0.6083 - val_binary_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 4s 530ms/step - loss: 0.2363 - binary_accuracy: 0.8500 - val_loss: 0.5836 - val_binary_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 4s 539ms/step - loss: 0.2086 - binary_accuracy: 0.9500 - val_loss: 0.5558 - val_binary_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 4s 511ms/step - loss: 0.2503 - binary_accuracy: 0.8500 - val_loss: 0.7892 - val_binary_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 4s 497ms/step - loss: 0.1037 - binary_accuracy: 1.0000 - val_loss: 0.7493 - val_binary_accuracy: 0.6667\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 4s 516ms/step - loss: 0.0789 - binary_accuracy: 1.0000 - val_loss: 0.7010 - val_binary_accuracy: 0.6667\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 0.1207 - binary_accuracy: 0.9500 - val_loss: 0.6028 - val_binary_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 4s 545ms/step - loss: 0.1046 - binary_accuracy: 1.0000 - val_loss: 0.6966 - val_binary_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 3s 497ms/step - loss: 0.0824 - binary_accuracy: 1.0000 - val_loss: 0.6066 - val_binary_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 4s 512ms/step - loss: 0.0381 - binary_accuracy: 1.0000 - val_loss: 0.5931 - val_binary_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 0.1639 - binary_accuracy: 0.9500 - val_loss: 0.6429 - val_binary_accuracy: 0.6667\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 4s 513ms/step - loss: 0.0530 - binary_accuracy: 1.0000 - val_loss: 0.8100 - val_binary_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ce8aedfa0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(train_gen,\n",
    "              validation_data = (testx, testy), \n",
    "              epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e2a390",
   "metadata": {},
   "source": [
    "#### 2.Freeze all layers except for the final convolutional layer of VGG16 + adding a few more dense layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40af471a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(vgg_model)\n",
    "new_model.add(Flatten())\n",
    "\n",
    "new_model.add(Dense(1024, activation = 'relu'))\n",
    "new_model.add(Dense(512, activation = 'relu'))\n",
    "new_model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5198cb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Almasria computer\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "new_model.compile(\n",
    "    optimizer = Adam(lr = 0.0001),\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"binary_accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bb860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 6s 682ms/step - loss: 0.9860 - binary_accuracy: 0.5000 - val_loss: 0.5652 - val_binary_accuracy: 0.6667\n",
      "Epoch 2/5\n",
      "2/7 [=======>......................] - ETA: 3s - loss: 0.1063 - binary_accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "new_model.fit(\n",
    "    train_gen,\n",
    "    validation_data = (testx,testy),\n",
    "    epochs = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a9157",
   "metadata": {},
   "source": [
    "#### 3.Freeze all layers except for the final convolutional layer of VGG16 + adding a few more dense layers and droupout layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(vgg_model)\n",
    "new_model.add(Flatten())\n",
    "\n",
    "new_model.add(Dense(1024, activation = 'relu'))\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Dense(512, activation = 'relu'))\n",
    "new_model.add(Dropout(0.5))\n",
    "new_model.add(Dense(256, activation = 'relu'))\n",
    "new_model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad267263",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(\n",
    "    optimizer = Adam(learning_rate = 0.0001),\n",
    "    loss = \"binary_crossentropy\",\n",
    "    metrics = [\"binary_accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bb2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = new_model.fit(\n",
    "    train_gen,\n",
    "    validation_data = (testx,testy),\n",
    "    epochs = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666b9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot( history.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Training Loss on Dataset\")\n",
    "    plt.xlabel(\"Epoch \")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef7e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(history):\n",
    "    plt.plot( history.history[\"binary_accuracy\"], label=\"train_acc\")\n",
    "    plt.plot(history.history[\"val_binary_accuracy\"], label=\"val_acc\")\n",
    "    plt.title(\"Training Accuracy\")\n",
    "    plt.xlabel(\"Epoch \")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4082344",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acc(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
